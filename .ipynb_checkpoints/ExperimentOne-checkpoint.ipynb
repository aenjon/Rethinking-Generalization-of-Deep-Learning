{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__使用keras中的mnist及cifar10。__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "num_classes = 0\n",
    "image_size = 0\n",
    "image_channel = 0\n",
    "data_set = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__全域變數們，所有訓練最多到1000epochs，並在training step設定early stopping。__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_cifar10():\n",
    "    global image_size, image_channel, num_classes, data_set\n",
    "    data_set = 'cifar10'\n",
    "    image_size = 32\n",
    "    image_channel = 3\n",
    "    num_classes = 10\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = scale_pixel_value(np.reshape(crop_image(x_train, crop_size), \n",
    "                                       [-1, (image_size - crop_size**2)**2 * image_channel]))\n",
    "    num_train = x_train.shape[0]\n",
    "    image_size = image_size - crop_size**2\n",
    "    return x_train, y_train\n",
    "\n",
    "def set_mnist():\n",
    "    global image_size, image_channel, num_classes, data_set\n",
    "    data_set = 'mnist'\n",
    "    image_size = 28\n",
    "    image_channel = 1\n",
    "    num_classes = 10\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape(x_train.shape[0], image_size**2 * image_channel)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_train /= 255\n",
    "    return x_train, y_train\n",
    "    \n",
    "def crop_image(images, c):\n",
    "    images = images[:, c:image_size-c, c:image_size-c]\n",
    "    return images\n",
    "\n",
    "def scale_pixel_value(images):\n",
    "    return images/255.\n",
    "\n",
    "def partially_corrupted_label(label, probability):\n",
    "    pcl = []\n",
    "    for l in label:\n",
    "        if np.random.random_sample() <= probability:\n",
    "            pcl.append(np.random.randint(0, num_classes))\n",
    "        else:\n",
    "            pcl.append(l)\n",
    "    return np.array(pcl)\n",
    "\n",
    "def random_label(label):\n",
    "    return np.reshape(np.random.randint(num_classes, size=len(label)), [-1,])\n",
    "\n",
    "def label_similarity(label1, label2):\n",
    "    counter = 0\n",
    "    print(label1.shape, label2.shape)\n",
    "    for l1, l2 in zip(label1, label2):\n",
    "        if l1 != l2:\n",
    "            counter += 1\n",
    "    return (len(label1) - float(counter)) / len(label1)\n",
    "\n",
    "def shuffled_pixel(images):\n",
    "    shuffled_images = []\n",
    "    permutation = np.random.permutation(image_size**2 * image_channel)\n",
    "    for image in images:\n",
    "        shuffled_image = []\n",
    "        for p in permutation:\n",
    "            shuffled_image.append(image[p])\n",
    "        shuffled_images.append(shuffled_image)\n",
    "    return np.array(shuffled_images)\n",
    "\n",
    "def gaussian(images, proportion):\n",
    "    pixel_num = len(images) * (image_size**2 * image_channel)\n",
    "    pixel = np.reshape(images, [pixel_num])\n",
    "    mean = pixel.mean()\n",
    "    variance_sum = np.ndarray.sum((pixel - mean)**2)\n",
    "    standard_deviation = np.sqrt(variance_sum / pixel_num)\n",
    "    temp = np.array(np.random.normal(loc=mean, scale=standard_deviation, \n",
    "                                     size=[(int)(len(images)*proportion), (image_size**2 * image_channel)]))\n",
    "    temp = temp.clip(0.0, 1.0)\n",
    "    return np.concatenate((images[:(int)(len(images)*(1 - proportion))], temp))\n",
    "    \n",
    "def random_pixel(images):\n",
    "    random_pixel_images = []\n",
    "    for image in images:\n",
    "        random_pixel_image = []\n",
    "        np.random.shuffle(image)\n",
    "        random_pixel_images.append(image)\n",
    "    return np.array(random_pixel_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, y_train, batch_size, hidden_size, layer, learning_rate):\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    #y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_size, activation='relu', input_shape=(image_size**2 * image_channel,)))\n",
    "    \n",
    "    for i in xrange(layer-1):\n",
    "        model.add(Dense(hidden_size, activation='relu'))\n",
    "        #model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr=learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,verbose=0)]\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_train, y_train), \n",
    "                        callbacks=callbacks)\n",
    "    with open('./%s/batch_size_%d_layer_%d_hidden_size_%d_summary' % (data_set, batch_size, layer, hidden_size), 'w') as fout:\n",
    "        orig_stdout = sys.stdout\n",
    "        sys.stdout = fout\n",
    "        print(model.summary())\n",
    "        sys.stdout = orig_stdout\n",
    "\n",
    "    return history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 16 layer: 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 13,002\n",
      "Trainable params: 13,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1000\n",
      "60000/60000 [==============================] - 0s - loss: 2.2512 - acc: 0.1651 - val_loss: 2.2008 - val_acc: 0.2158\n",
      "Epoch 2/1000\n",
      "60000/60000 [==============================] - 0s - loss: 2.1485 - acc: 0.2527 - val_loss: 2.0883 - val_acc: 0.2919\n",
      "Epoch 3/1000\n",
      "60000/60000 [==============================] - 0s - loss: 2.0227 - acc: 0.3279 - val_loss: 1.9510 - val_acc: 0.3638\n",
      "Epoch 4/1000\n",
      "60000/60000 [==============================] - 0s - loss: 1.8804 - acc: 0.4015 - val_loss: 1.8050 - val_acc: 0.4464\n",
      "Epoch 5/1000\n",
      "60000/60000 [==============================] - 0s - loss: 1.7317 - acc: 0.4852 - val_loss: 1.6538 - val_acc: 0.5259\n",
      "Epoch 6/1000\n",
      "60000/60000 [==============================] - 0s - loss: 1.5794 - acc: 0.5629 - val_loss: 1.5010 - val_acc: 0.5981\n",
      "Epoch 7/1000\n",
      "60000/60000 [==============================] - 0s - loss: 1.4273 - acc: 0.6272 - val_loss: 1.3505 - val_acc: 0.6550\n",
      "Epoch 8/1000\n",
      "60000/60000 [==============================] - 0s - loss: 1.2809 - acc: 0.6736 - val_loss: 1.2097 - val_acc: 0.6939\n",
      "Epoch 9/1000\n",
      "60000/60000 [==============================] - 0s - loss: 1.1477 - acc: 0.7068 - val_loss: 1.0856 - val_acc: 0.7192\n",
      "Epoch 10/1000\n",
      "60000/60000 [==============================] - 0s - loss: 1.0333 - acc: 0.7284 - val_loss: 0.9813 - val_acc: 0.7359\n",
      "Epoch 11/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.9382 - acc: 0.7440 - val_loss: 0.8955 - val_acc: 0.7529\n",
      "Epoch 12/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.8604 - acc: 0.7601 - val_loss: 0.8254 - val_acc: 0.7682\n",
      "Epoch 13/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.7965 - acc: 0.7756 - val_loss: 0.7676 - val_acc: 0.7813\n",
      "Epoch 14/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.7435 - acc: 0.7885 - val_loss: 0.7190 - val_acc: 0.7966\n",
      "Epoch 15/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.6985 - acc: 0.8038 - val_loss: 0.6777 - val_acc: 0.8117\n",
      "Epoch 16/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.6601 - acc: 0.8163 - val_loss: 0.6421 - val_acc: 0.8231\n",
      "Epoch 17/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.6270 - acc: 0.8269 - val_loss: 0.6112 - val_acc: 0.8312\n",
      "Epoch 18/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.5981 - acc: 0.8356 - val_loss: 0.5844 - val_acc: 0.8391\n",
      "Epoch 19/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.5729 - acc: 0.8429 - val_loss: 0.5609 - val_acc: 0.8464\n",
      "Epoch 20/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.5508 - acc: 0.8489 - val_loss: 0.5401 - val_acc: 0.8513\n",
      "Epoch 21/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.5313 - acc: 0.8533 - val_loss: 0.5218 - val_acc: 0.8559\n",
      "Epoch 22/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.5140 - acc: 0.8578 - val_loss: 0.5056 - val_acc: 0.8599\n",
      "Epoch 23/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.4987 - acc: 0.8615 - val_loss: 0.4912 - val_acc: 0.8631\n",
      "Epoch 24/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.4850 - acc: 0.8643 - val_loss: 0.4783 - val_acc: 0.8664\n",
      "Epoch 25/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.4728 - acc: 0.8678 - val_loss: 0.4666 - val_acc: 0.8690\n",
      "Epoch 26/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.4617 - acc: 0.8700 - val_loss: 0.4562 - val_acc: 0.8720\n",
      "Epoch 27/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.4517 - acc: 0.8727 - val_loss: 0.4467 - val_acc: 0.8743\n",
      "Epoch 28/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.4426 - acc: 0.8756 - val_loss: 0.4380 - val_acc: 0.8768\n",
      "Epoch 29/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.4343 - acc: 0.8776 - val_loss: 0.4300 - val_acc: 0.8789\n",
      "Epoch 30/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.4265 - acc: 0.8792 - val_loss: 0.4230 - val_acc: 0.8802\n",
      "Epoch 31/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.4196 - acc: 0.8811 - val_loss: 0.4159 - val_acc: 0.8823\n",
      "Epoch 32/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.4131 - acc: 0.8829 - val_loss: 0.4097 - val_acc: 0.8840\n",
      "Epoch 33/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.4070 - acc: 0.8842 - val_loss: 0.4039 - val_acc: 0.8848\n",
      "Epoch 34/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.4014 - acc: 0.8855 - val_loss: 0.3986 - val_acc: 0.8858\n",
      "Epoch 35/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3963 - acc: 0.8866 - val_loss: 0.3933 - val_acc: 0.8876\n",
      "Epoch 36/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3913 - acc: 0.8879 - val_loss: 0.3888 - val_acc: 0.8884\n",
      "Epoch 37/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3867 - acc: 0.8893 - val_loss: 0.3843 - val_acc: 0.8897\n",
      "Epoch 38/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3824 - acc: 0.8905 - val_loss: 0.3800 - val_acc: 0.8909\n",
      "Epoch 39/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3783 - acc: 0.8912 - val_loss: 0.3760 - val_acc: 0.8923\n",
      "Epoch 40/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3744 - acc: 0.8925 - val_loss: 0.3725 - val_acc: 0.8926\n",
      "Epoch 41/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3709 - acc: 0.8935 - val_loss: 0.3687 - val_acc: 0.8943\n",
      "Epoch 42/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3673 - acc: 0.8947 - val_loss: 0.3653 - val_acc: 0.8955\n",
      "Epoch 43/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3641 - acc: 0.8955 - val_loss: 0.3621 - val_acc: 0.8960\n",
      "Epoch 44/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3609 - acc: 0.8965 - val_loss: 0.3591 - val_acc: 0.8970\n",
      "Epoch 45/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3579 - acc: 0.8972 - val_loss: 0.3562 - val_acc: 0.8977\n",
      "Epoch 46/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3550 - acc: 0.8983 - val_loss: 0.3535 - val_acc: 0.8983\n",
      "Epoch 47/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3523 - acc: 0.8987 - val_loss: 0.3506 - val_acc: 0.8992\n",
      "Epoch 48/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3496 - acc: 0.8991 - val_loss: 0.3483 - val_acc: 0.8998\n",
      "Epoch 49/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3471 - acc: 0.9002 - val_loss: 0.3459 - val_acc: 0.8996\n",
      "Epoch 50/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3447 - acc: 0.9007 - val_loss: 0.3433 - val_acc: 0.9013\n",
      "Epoch 51/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3423 - acc: 0.9011 - val_loss: 0.3409 - val_acc: 0.9013\n",
      "Epoch 52/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3400 - acc: 0.9018 - val_loss: 0.3386 - val_acc: 0.9018\n",
      "Epoch 53/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3379 - acc: 0.9021 - val_loss: 0.3364 - val_acc: 0.9025\n",
      "Epoch 54/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3357 - acc: 0.9027 - val_loss: 0.3343 - val_acc: 0.9028\n",
      "Epoch 55/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3336 - acc: 0.9032 - val_loss: 0.3325 - val_acc: 0.9033\n",
      "Epoch 56/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3317 - acc: 0.9038 - val_loss: 0.3305 - val_acc: 0.9042\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s - loss: 0.3297 - acc: 0.9044 - val_loss: 0.3286 - val_acc: 0.9045\n",
      "Epoch 58/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3279 - acc: 0.9052 - val_loss: 0.3265 - val_acc: 0.9053\n",
      "Epoch 59/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3260 - acc: 0.9054 - val_loss: 0.3248 - val_acc: 0.9060\n",
      "Epoch 60/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3241 - acc: 0.9062 - val_loss: 0.3233 - val_acc: 0.9062\n",
      "Epoch 61/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3225 - acc: 0.9063 - val_loss: 0.3214 - val_acc: 0.9067\n",
      "Epoch 62/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3208 - acc: 0.9067 - val_loss: 0.3196 - val_acc: 0.9071\n",
      "Epoch 63/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3191 - acc: 0.9074 - val_loss: 0.3180 - val_acc: 0.9075\n",
      "Epoch 64/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3175 - acc: 0.9081 - val_loss: 0.3165 - val_acc: 0.9078\n",
      "Epoch 65/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3159 - acc: 0.9082 - val_loss: 0.3148 - val_acc: 0.9087\n",
      "Epoch 66/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3145 - acc: 0.9090 - val_loss: 0.3133 - val_acc: 0.9093\n",
      "Epoch 67/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3128 - acc: 0.9088 - val_loss: 0.3118 - val_acc: 0.9095\n",
      "Epoch 68/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3115 - acc: 0.9096 - val_loss: 0.3105 - val_acc: 0.9100\n",
      "Epoch 69/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3099 - acc: 0.9102 - val_loss: 0.3091 - val_acc: 0.9102\n",
      "Epoch 70/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3085 - acc: 0.9106 - val_loss: 0.3077 - val_acc: 0.9109\n",
      "Epoch 71/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3072 - acc: 0.9113 - val_loss: 0.3064 - val_acc: 0.9105\n",
      "Epoch 72/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3058 - acc: 0.9113 - val_loss: 0.3049 - val_acc: 0.9114\n",
      "Epoch 73/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3045 - acc: 0.9116 - val_loss: 0.3036 - val_acc: 0.9121\n",
      "Epoch 74/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3033 - acc: 0.9121 - val_loss: 0.3022 - val_acc: 0.9126\n",
      "Epoch 75/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3020 - acc: 0.9126 - val_loss: 0.3012 - val_acc: 0.9128\n",
      "Epoch 76/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.3008 - acc: 0.9131 - val_loss: 0.2999 - val_acc: 0.9129\n",
      "Epoch 77/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2996 - acc: 0.9133 - val_loss: 0.2986 - val_acc: 0.9138\n",
      "Epoch 78/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2983 - acc: 0.9137 - val_loss: 0.2976 - val_acc: 0.9139\n",
      "Epoch 79/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2972 - acc: 0.9137 - val_loss: 0.2965 - val_acc: 0.9140\n",
      "Epoch 80/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2961 - acc: 0.9139 - val_loss: 0.2951 - val_acc: 0.9143\n",
      "Epoch 81/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2949 - acc: 0.9145 - val_loss: 0.2941 - val_acc: 0.9150\n",
      "Epoch 82/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2938 - acc: 0.9150 - val_loss: 0.2932 - val_acc: 0.9148\n",
      "Epoch 83/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2928 - acc: 0.9154 - val_loss: 0.2918 - val_acc: 0.9157\n",
      "Epoch 84/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2916 - acc: 0.9159 - val_loss: 0.2907 - val_acc: 0.9160\n",
      "Epoch 85/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2906 - acc: 0.9162 - val_loss: 0.2897 - val_acc: 0.9160\n",
      "Epoch 86/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2895 - acc: 0.9166 - val_loss: 0.2891 - val_acc: 0.9160\n",
      "Epoch 87/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2885 - acc: 0.9167 - val_loss: 0.2878 - val_acc: 0.9166\n",
      "Epoch 88/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2876 - acc: 0.9165 - val_loss: 0.2867 - val_acc: 0.9171\n",
      "Epoch 89/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2866 - acc: 0.9170 - val_loss: 0.2857 - val_acc: 0.9173\n",
      "Epoch 90/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2856 - acc: 0.9174 - val_loss: 0.2847 - val_acc: 0.9177\n",
      "Epoch 91/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2846 - acc: 0.9176 - val_loss: 0.2838 - val_acc: 0.9181\n",
      "Epoch 92/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2837 - acc: 0.9181 - val_loss: 0.2829 - val_acc: 0.9185\n",
      "Epoch 93/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2828 - acc: 0.9183 - val_loss: 0.2819 - val_acc: 0.9186\n",
      "Epoch 94/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2819 - acc: 0.9186 - val_loss: 0.2811 - val_acc: 0.9192\n",
      "Epoch 95/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2809 - acc: 0.9188 - val_loss: 0.2801 - val_acc: 0.9192\n",
      "Epoch 96/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2800 - acc: 0.9191 - val_loss: 0.2794 - val_acc: 0.9191\n",
      "Epoch 97/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2792 - acc: 0.9194 - val_loss: 0.2784 - val_acc: 0.9195\n",
      "Epoch 98/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2783 - acc: 0.9197 - val_loss: 0.2777 - val_acc: 0.9196\n",
      "Epoch 99/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2776 - acc: 0.9199 - val_loss: 0.2768 - val_acc: 0.9202\n",
      "Epoch 100/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2767 - acc: 0.9204 - val_loss: 0.2760 - val_acc: 0.9202\n",
      "Epoch 101/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2758 - acc: 0.9206 - val_loss: 0.2751 - val_acc: 0.9206\n",
      "Epoch 102/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2750 - acc: 0.9209 - val_loss: 0.2743 - val_acc: 0.9207\n",
      "Epoch 103/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2742 - acc: 0.9208 - val_loss: 0.2735 - val_acc: 0.9210\n",
      "Epoch 104/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2735 - acc: 0.9211 - val_loss: 0.2726 - val_acc: 0.9215\n",
      "Epoch 105/1000\n",
      "60000/60000 [==============================] - 0s - loss: 0.2726 - acc: 0.9214 - val_loss: 0.2719 - val_acc: 0.9217\n",
      "Epoch 106/1000\n",
      "54272/60000 [==========================>...] - ETA: 0s - loss: 0.2708 - acc: 0.9217"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-88b3c513ecb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hidden_size: %d layer: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./%s/%d_batch_size_%d_layer_%d_hidden_size_%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-3482e501365c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(x_train, y_train, batch_size, hidden_size, layer, learning_rate)\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./%s/batch_size_%d_layer_%d_hidden_size_%d_summary'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0morig_stdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1153\u001b[0m                         val_outs = self._test_loop(val_f, val_ins,\n\u001b[1;32m   1154\u001b[0m                                                    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m                                                    verbose=0)\n\u001b[0m\u001b[1;32m   1156\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m                             \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train , y_train = set_mnist()\n",
    "batch_size = 1024\n",
    "learning_rate = 0.01\n",
    "hidden_size = [16, 128, 512, 1024]\n",
    "layer = [2, 4, 6, 8, 10]\n",
    "\n",
    "for i in xrange(3):\n",
    "    for size in hidden_size:\n",
    "        for l in layer:\n",
    "            print('hidden_size: %d layer: %d' % (size, l))\n",
    "            history = train(x_train, y_train, batch_size=batch_size, hidden_size=size, layer=l, learning_rate=learning_rate)\n",
    "            with open('./%s/%d_batch_size_%d_layer_%d_hidden_size_%d' % (data_set, i+1, batch_size, l, size), 'w') as fout:\n",
    "                json.dump(history, fout)\n",
    "    break\n",
    "\n",
    "for i in xrange(3):\n",
    "    for size in hidden_size:\n",
    "        for l in layer:\n",
    "            print('random label hidden_size: %d layer: %d' % (size, l))\n",
    "            history = train_mnist(x_train, random_label(y_train), batch_size=batch_size, hidden_size=size, layer=l, learning_rate=learning_rate)\n",
    "            with open('./%s/%d_random_label_batch_size_%d_layer_%d_hidden_size_%d' % (data_set, i+1, batch_size, l, size), 'w') as fout:\n",
    "                json.dump(history, fout)\n",
    "    break\n",
    "\n",
    "gaussian_proportion = [.2, .4, .6, .8, 1.]\n",
    "\n",
    "for i in xrange(3):\n",
    "    for proportion in gaussian_proportion:\n",
    "        for size in hidden_size:\n",
    "            for l in layer:\n",
    "                print('gausson: %f hidden_size: %d layer: %d' % (proportion, size, l))\n",
    "                history = train_mnist(gaussian(x_train, proportion), y_train, batch_size=batch_size, hidden_size=size, layer=l, learning_rate=learning_rate)\n",
    "                with open('./%s/%d_gaussian_%f_batch_size_%d_layer_%d_hidden_size_%d' % (data_set, i+1, proportion, batch_size, l, size), 'w') as fout:\n",
    "                    json.dump(history, fout)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
